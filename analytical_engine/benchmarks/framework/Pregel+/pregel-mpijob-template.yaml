apiVersion: kubeflow.org/v2beta1
kind: MPIJob
metadata:
  name: pregel-mpijob
spec:
  slotsPerWorker: ${SLOTS_PER_WORKER}          
  runPolicy:
    cleanPodPolicy: None
    ttlSecondsAfterFinished: 120
  sshAuthMountPath: /home/mpiuser/.ssh

  mpiReplicaSpecs:
    Launcher:
      replicas: 1
      template:
        spec:
          restartPolicy: OnFailure
          volumes:
            - name: hadoop-config
              configMap:
                name: my-hadoop-cluster-hadoop   
            - name: scratch
              emptyDir: {}
            - name: pregeldata
              hostPath:
                path: ${HOST_PATH}
                type: Directory

            
          containers:
            - name: mpi-launcher
              image: pregel-mpi:v0.1      
              imagePullPolicy: IfNotPresent
              securityContext:
                runAsUser: 1000
              env:
                - name: HADOOP_CONF_DIR
                  value: "/etc/hadoop"

                - name: HDFS_NN_SERVICE
                  value: my-hadoop-cluster-hadoop-hdfs-nn
                - name: HDFS_NN_PORT
                  value: "9000"                   

                - name: CLEAN_OUTPUT
                  value: "1"

                - name: JAVA_HOME
                  value: /usr/lib/jvm/java-17-openjdk-amd64
                - name: PATH
                  value: "$(JAVA_HOME)/bin:/usr/local/hadoop/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"


              volumeMounts:
                - name: hadoop-config
                  mountPath: /etc/hadoop
                - name: scratch
                  mountPath: /opt/scratch
                - name: pregeldata
                  mountPath: /opt/data/

              command: ["/bin/bash"]
              args:
                - "-c"
                - |

                    echo "[INFO] Waiting 10s for network/DNS to fully ready..."
                    sleep 10
                    echo "[INFO] Preparing HDFS data for dataset: ${DATASET}"
                    DATASET_HDFS_PATH="/user/mpiuser/${DATASET}"

                    if hdfs dfs -test -e "${DATASET_HDFS_PATH}"; then
                       echo "[INFO] Dataset already exists on HDFS."
                    else
                        
                        echo "[INFO] Dataset not found on HDFS, uploading..."
                        HADOOP_USER_NAME=root hdfs dfs -mkdir -p /user/mpiuser
                        HADOOP_USER_NAME=root hdfs dfs -chown mpiuser:supergroup /user/mpiuser
                        HADOOP_USER_NAME=root hdfs dfs -chmod 775 /user/mpiuser
                        hdfs dfs -put "/opt/data/${DATASET}" "${DATASET_HDFS_PATH}"
                        
                    fi
                    echo "[INFO] HDFS data is ready."

                    hdfs dfs -ls /user/mpiuser/

                    cat /etc/hadoop/core-site.xml

                    HADOOP_CP=$(cat /etc/hadoop_classpath)
                    
                    time mpiexec \
                      -np ${MPIRUN_NP} \
                      -hostfile /etc/mpi/hostfile \
                      -verbose \
                      -x CLASSPATH="$(cat /etc/hadoop_classpath)" \
                      -x LD_LIBRARY_PATH="/usr/lib/jvm/java-17-openjdk-amd64/lib/server:/usr/local/hadoop/lib/native:/usr/local/bin:/usr/local/lib:/usr/local/openmpi/bin:/usr/local/openmpi/lib" \
                      -x JAVA_HOME="/usr/lib/jvm/java-17-openjdk-amd64" \
                      -x HADOOP_CONF_DIR="/etc/hadoop" \
                      /opt/pregel+/${ALGORITHM}/run "${DATASET_HDFS_PATH}"

              resources:
                limits:
                  cpu: ${CPU}
                  memory: ${MEMORY}
                requests:
                  cpu: ${CPU}
                  memory: ${MEMORY}

    Worker:
      replicas: ${REPLICAS}
      template:
        spec:
          restartPolicy: OnFailure
          volumes:
            - name: hadoop-config
              configMap:
                name: my-hadoop-cluster-hadoop
            - name: scratch
              emptyDir: {}
            - name: pregeldata
              hostPath:
                path: ${HOST_PATH}
                type: Directory
          containers:
            - name: mpi-worker
              image: pregel-mpi:v0.1    
              imagePullPolicy: IfNotPresent
              securityContext:
                runAsUser: 1000
              env:
                - name: JAVA_HOME
                  value: /usr/lib/jvm/java-17-openjdk-amd64
                - name: PATH
                  value: "$(JAVA_HOME)/bin:/usr/local/hadoop/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
                - name: HADOOP_CONF_DIR
                  value: "/etc/hadoop"
                - name: HDFS_NN_SERVICE
                  value: my-hadoop-cluster-hadoop-hdfs-nn
                - name: HDFS_NN_PORT
                  value: "9000"  


              volumeMounts:
                - name: hadoop-config
                  mountPath: /etc/hadoop
                - name: scratch
                  mountPath: /opt/scratch
                - name: pregeldata
                  mountPath: /opt/data/
              command: ["/usr/sbin/sshd"]
              args: ["-De","-f","/home/mpiuser/.sshd_config"]
              resources:
                limits:
                  cpu: ${CPU}
                  memory: ${MEMORY}
                requests:
                  cpu: ${CPU}
                  memory: ${MEMORY}
